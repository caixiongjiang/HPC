## UC Berkeley CS267

### 介绍

例子：`n`个数相加，串行处理器需要执行`n`次操作，而两个并行处理器只需要`logn`次。



> 什么是并行计算机？



并行计算机一般分为3种：

* 共享内存多处理器（SMP）：所有处理器都连接到单个内存
* 高性能计算机(HPC)/分布式内存多处理器：有多个处理器和单独的内存，他们通过网络相互连接。
* 单指令多数据处理器（SIMD）：单个处理器但拥有多个处理单元，这些处理单元类似于逻辑处理器。（所有的处理单元在完全相同的步骤上运行相同的程序）

![](https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img1.jpg)



> 并发和并行有什么区别？



并发是指同时处理多个任务的能力。当一个系统能够处理多个任务，并且这些任务在时间上有重叠，即任务之间可能交替执行、互相切换，但不一定同时进行。并发是一种逻辑上的概念，它关注的是任务的组织和调度，以实现高效的任务处理。在并发系统中，任务之间可以通过线程、进程、事件驱动等方式进行交互和通信。

并行是指同时执行多个任务的能力。当一个系统能够同时处理多个任务，任务之间的执行是真正的同时进行，各个任务可以利用系统的多个处理单元（例如多个CPU核心）来并行执行。并行是一种物理上的概念，它关注的是任务的实际执行，以提高系统的整体性能。

![](https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img2.jpg)



> HPC的计量单位



- Flop：浮点运算，除非注明，通常表示双精度

- Flop/s：计算每秒可以执行浮点运算的次数
- Bytes：数据的大小（双精度浮点数表示8字节）
- 典型的计量大小：

![](https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img3.jpg)



> 课程整体安排



![](https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img4.jpg)



### 内存层次结构和矩阵乘法

#### 编译器

编译器就是将C、C++等高级语言转化为机器语言的转化工具。

例子：

```c++
void main() {
  c = a + b;
}
```

上面这c++段代码会被转化成汇编语言指令：

```c++
void main() {
	//R1 和 R2都为寄存器，a，b，c都来自内存
	Load a into R1
	Load b into R2
	R3 = R1 + R2
	Store R3 into c
}
```



#### 单处理器模型

* 内存访问（加载/存储）有两个成本：

​	-- Latency：加载/存储一个词的成本($a$)

​	-- Bandwidth(带宽):加载/存储一个大块的平均速率($\beta$)

可以通过下面这张图来区分它们，延迟代表数据流动的成本，而带宽代表”水管“的宽度：

![](https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img5.jpg)

* 大多数项目都具有高度的局部性：

​	-- 空间局部性：访问附近的事物

​	-- 时间局部性：重复以前访问过的项目

* 缓存是快速（昂贵）的内存，可以保存数据的副本，它对于软件（上层代码）是隐藏的。
* 缓存命中成本：缓存正好有我们需要的数据，加载这个数据需要更少的成本
* 缓存未命中成本：这相对于缓存命中是更昂贵的。（比直接查询内存成本还要高）



> 为什么需要有多级缓存？

越高速的缓存造价越高，所以需要使用多级缓存来降低成本。



> 处理内存延迟的方法

*  重用快速内存中的值（利用程序中的时间局部性）
* 移动更大的块（带宽允许的情况）
* 从单个指令中发出多个读/写，例如，矢量操作需要访问一组位置，它们通常是相邻的
* 并行发出多个读/写（隐藏延迟），要求发生的两个操作没有依赖关系

> 内存基准（CacheBench）

内存系统性能的Microbenchmark伪代码:

```
for v1 = all vector lengths
	memory[v1]
	time start
	for iteration count
		for i=0 to v1
		register r += memory[i]
	time stop
```



> 串行处理器为什么也有一定的并行性？

* 流水线执行：

使用一个洗衣服的例子，单件衣服总时间 = wash（30min）+ dry（40min）+ fold（20min）

那么洗4件衣服需要的总时间 = 30 + 40 + 40 + 40 + 40 + 20 = 210min

![](https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img6.jpg)



* SIMD（单一指令，多个数据）

这种并行方式对软件（上层代码）是可见的。SIMD指令是一个向量指令，它并不是加载单个变量，而是加载变量数组，如下图所示：

![](https://blog-1311257248.cos.ap-nanjing.myqcloud.com/imgs/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/img7.jpg)



* 数据依赖限制并行

如果指令必须按照顺序执行，那么并行执行会得到错误的答案。

1.读后写（RAW）`X = A; B = X`

2.写后读（WAR）`A = X; X = B`

3.写后写（WAW）`X = A; X = B`

4.读后读，这对并行性没有限制。



#### 矩阵乘法

> 矩阵乘法的优化



一个简单的内存模型：

1.假设两个层次的内存结构，快速的和慢速的

2.所有的数据都在慢的内存上进行初始化：

​	-- $m$代表在快慢内存中的元素个数

​	-- $t_m$代表每次慢速内存操作花费的时间

​	--$f$代表算数运算的次数

​	--$t_f$代表每次算数运算的时间

​	--$CI = f/m$代表每个慢速内存访问的平均（用来衡量计算强度）

所以，最小的计算时间为（理论）：$time = f * t_f$，当所有的数据都在快速内存中。

实际的时间：$time = f*t_f + m * t_m = f*t*(1 + t_m/t_f + 1/CI)$，所以算法的关键效率在于$CI$， 机器的平衡效率关键在$t_m/t_f$。



例子1：

```python
for i in range(n):
  for j in range(n):
    y[i] = y[i] + A[i][j] * x[j]
# 策略：
# {读取 x[1:n]到快速内存}
# {读取 y[1:n]到慢速内存}
# 将A的第i行读入快速内存
# 将y[1:n]的结果写回慢速内存
# 这样的策略 m = 3n + n^2, f = 2n^2, CI = f/m 约为2（计算强度低）
```

这说明矩阵乘法会受到内存速度的限制。



例子2：

```python
for i in range(n):
  for j in range(n):
    for k in range(n):
      c[i][j] = c[i][j] + A[i][k] * B[k][j]
# 策略：
# 读取A的第i行到快速内存
# 读取c[i][j]到快速内存
# 读取B的第j列到快速内存
# 将c[i][j]的内容写回慢速内存
# 这样的策略 m = n^3 + n^2 + 2n^2， CI = f/m = 2n^3/(n^3 + 3n^2) 

# 加速策略1是平铺缓存，读取的时候可以按列读取，而不是单个元素的读取
# 加速策略2是平铺寄存器，如果c、A、B的矩阵大小很小，只有2*2时，可以使用寄存器直接进行分配计算
```



